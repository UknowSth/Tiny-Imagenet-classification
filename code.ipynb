{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch.nn as nn\r\n",
    "import torch\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pickle\r\n",
    "import numpy as np\r\n",
    "import torch.nn.functional as F\r\n",
    "import os\r\n",
    "import torchvision"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "if torch.cuda.is_available():\r\n",
    "    device = torch.device(\"cuda\")\r\n",
    "else:\r\n",
    "    device = torch.device(\"cpu\")\r\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.数据读取"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 直接读取数据，没有数据增强\r\n",
    "def get_data(size=64,batch_size=128):\r\n",
    "    train_transform = torchvision.transforms.Compose([\r\n",
    "        torchvision.transforms.Resize(size=(size, size)),\r\n",
    "        torchvision.transforms.ToTensor(),\r\n",
    "        ]) # 是否需要Normalization? torchvision.transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\r\n",
    "    train_dataset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/train', transform=train_transform)\r\n",
    "    val_dataset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/val', transform=train_transform)\r\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\r\n",
    "    test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\r\n",
    "    print('Successfully load data!')\r\n",
    "    return train_loader,test_loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 训练集的标签按照文件名的顺序开始 验证集的标签自行确定\r\n",
    "train_loader,val_loader = get_data(batch_size=128) # 一般使用batch为128"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully load data!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# 验证集的标签需要额外获取\r\n",
    "# 测试集顺序获取标签 从而获得验证集的标签\r\n",
    "TrainList = os.listdir('./tiny-imagenet-200/train/')\r\n",
    "ValList = os.listdir('./tiny-imagenet-200/val/images')\r\n",
    "# 生成两个字典 获取验证集的标签\r\n",
    "NameToLabel = {}\r\n",
    "ValnameToLabel = {}\r\n",
    "for i,trainPath in enumerate(TrainList):\r\n",
    "    NameToLabel[trainPath] = i\r\n",
    "val_label = torch.zeros(10000)\r\n",
    "file_class = {}\r\n",
    "with open('./tiny-imagenet-200/val/val_annotations.txt','r',encoding='utf-8')as f:\r\n",
    "    labels = f.readlines()\r\n",
    "    for label in labels:\r\n",
    "        ValnameToLabel[label.split('\\t')[0]] = NameToLabel[label.split('\\t')[1]]\r\n",
    "# 字典完成后获取标签\r\n",
    "for i,path in enumerate(ValList):\r\n",
    "    val_label[i] = ValnameToLabel[path]\r\n",
    "print(val_label[:5])\r\n",
    "val_label = val_label.to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([107., 139., 158.,  90., 138.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 对于任务1中某些模型需要数据增强的方法提供支持"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "trainList = [\r\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.6),\r\n",
    "        torchvision.transforms.RandomVerticalFlip(p=0.6),\r\n",
    "        torchvision.transforms.RandomRotation(degrees=20),\r\n",
    "        torchvision.transforms.ColorJitter(brightness=0, contrast=[0.9,1.08], saturation=0, hue=0)\r\n",
    "    ]\r\n",
    "valCope= torchvision.transforms.CenterCrop(56)\r\n",
    "trainCope = torchvision.transforms.Compose([\r\n",
    "    torchvision.transforms.RandomCrop(size=56),\r\n",
    "    torchvision.transforms.RandomChoice(trainList),\r\n",
    "    ])\r\n",
    "def getdata_task1_aug(X,mode='train'):\r\n",
    "    if mode == 'train':\r\n",
    "        X = trainCope(X)\r\n",
    "    elif mode == 'val':\r\n",
    "        X = valCope(X)\r\n",
    "    else:\r\n",
    "        print('error!')\r\n",
    "    return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 对于任务1中DenseNet需要数据增强的方法提供支持"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "dataList = [\r\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\r\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.2),\r\n",
    "    torchvision.transforms.GaussianBlur(kernel_size=3,sigma=(0.1,2.0)),\r\n",
    "    torchvision.transforms.RandomCrop(64, padding=10, pad_if_needed=False, fill=0, padding_mode='constant'),\r\n",
    "    torchvision.transforms.RandomAffine(degrees=45, translate=(0.2,0.2), shear=16)\r\n",
    "]\r\n",
    "dataCope = torchvision.transforms.RandomApply(dataList, p=0.5)\r\n",
    "def get_data_for_densenet(X):\r\n",
    "    X = dataCope(X)\r\n",
    "    return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "低配版Mask（本质上也是一种数据增强的方法）"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "from typing import Any, Callable, Optional, Tuple\r\n",
    "from torchvision.datasets.folder import DatasetFolder, default_loader, IMG_EXTENSIONS\r\n",
    "import albumentations as A\r\n",
    "\r\n",
    "class Transforms:\r\n",
    "    def __init__(self, transforms: A.Compose):\r\n",
    "        self.transforms = transforms\r\n",
    "\r\n",
    "    def __call__(self, img, *args, **kwargs):\r\n",
    "        return self.transforms(image=np.array(img))['image']\r\n",
    "\r\n",
    "class CustomImageFolder(DatasetFolder):\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        root: str,\r\n",
    "        transform: Optional[Callable] = None,\r\n",
    "        target_transform: Optional[Callable] = None,\r\n",
    "        loader: Callable[[str], Any] = default_loader,\r\n",
    "        is_valid_file: Optional[Callable[[str], bool]] = None,\r\n",
    "    ):\r\n",
    "        super().__init__(\r\n",
    "            root,\r\n",
    "            loader,\r\n",
    "            IMG_EXTENSIONS if is_valid_file is None else None,\r\n",
    "            transform=transform,\r\n",
    "            target_transform=target_transform,\r\n",
    "            is_valid_file=is_valid_file,\r\n",
    "        )\r\n",
    "        self.imgs = self.samples\r\n",
    "\r\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\r\n",
    "        \"\"\"\r\n",
    "        Args:\r\n",
    "            index (int): Index\r\n",
    "\r\n",
    "        Returns:\r\n",
    "            tuple: (sample, target) where target is class_index of the target class.\r\n",
    "        \"\"\"\r\n",
    "        path, target = self.samples[index]\r\n",
    "        sample = self.loader(path)\r\n",
    "        if self.transform is not None:\r\n",
    "            try:\r\n",
    "                sample = self.transform(sample)\r\n",
    "            except Exception:\r\n",
    "                sample = self.transform(image=np.array(sample))[\"image\"]\r\n",
    "        if self.target_transform is not None:\r\n",
    "            target = self.target_transform(target)\r\n",
    "\r\n",
    "        return sample, target\r\n",
    "\r\n",
    "    def __len__(self) -> int:\r\n",
    "        return len(self.samples)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 对于加了噪声和没加噪声的数据，要保证打乱后的顺序一致\r\n",
    "trainset_masked = CustomImageFolder(root='./tiny-imagenet-200/train',transform=Transforms(transforms=A.Cutout(num_holes=12, max_h_size=16, max_w_size=16, fill_value=0, always_apply=False, p=1)))\r\n",
    "trainset_nomask = CustomImageFolder(root='./tiny-imagenet-200/train',transform=Transforms(transforms=A.Resize(64,64)))\r\n",
    "torch.manual_seed(0)\r\n",
    "g = torch.Generator()\r\n",
    "train_loader_masked = torch.utils.data.DataLoader(trainset_masked, batch_size=128, shuffle=True,generator=g)\r\n",
    "torch.manual_seed(0)\r\n",
    "g = torch.Generator()\r\n",
    "train_loader_nomask = torch.utils.data.DataLoader(trainset_nomask, batch_size=128, shuffle=True,generator=g)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.任务1"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 首先尝试AlexNet，可以作为baseline"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def train_task1(model,epoch=100,lr=0.001):\r\n",
    "    loss_function = nn.CrossEntropyLoss()\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-4) # 学习率有待调整\r\n",
    "    schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=32)\r\n",
    "    # optimizer = torch.optim.SGD(model.parameters(),momentum=0.9,lr=lr,weight_decay=1e-4)\r\n",
    "    lossRec = []\r\n",
    "    validRec = []\r\n",
    "\r\n",
    "    for i in range(epoch):\r\n",
    "        running_loss = 0.0\r\n",
    "        for data in train_loader:\r\n",
    "            imgs,target = data\r\n",
    "            imgs = imgs.to(device)\r\n",
    "            target = target.to(device)\r\n",
    "            output = model(imgs)    \r\n",
    "            loss = loss_function(output,target)\r\n",
    "            running_loss += loss.item()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.zero_grad()\r\n",
    "        lossRec.append(running_loss/len(train_loader))\r\n",
    "        print('Epoch: [{}/{}],TrainLoss:{:.5f}'.format(i+1,epoch,running_loss/len(train_loader))) \r\n",
    "\r\n",
    "        with torch.no_grad():\r\n",
    "            correct_num = 0\r\n",
    "            all_num = 0\r\n",
    "            Pred = torch.zeros(0)\r\n",
    "            Pred = Pred.to(device)\r\n",
    "            for data in val_loader:\r\n",
    "                imgs,_ = data\r\n",
    "                pred = model(imgs.to(device))\r\n",
    "                prob = torch.softmax(pred,dim=1)\r\n",
    "                y_pred = torch.argmax(prob,dim=1)\r\n",
    "                Pred = torch.concat((Pred,y_pred),0)\r\n",
    "            acc = torch.sum(Pred == val_label)/Pred.shape[0]\r\n",
    "            print('TestAcc:{:.4f}'.format(acc))\r\n",
    "            validRec.append(acc.cpu().item())\r\n",
    "\r\n",
    "        schedule.step()\r\n",
    "        torch.save(model,'./AlexNet/AlexNet_{}.pt'.format(i+1+7))\r\n",
    "\r\n",
    "    t = range(1,len(lossRec)+1)\r\n",
    "    plt.figure(figsize=(18,10))\r\n",
    "    plt.subplot(121)\r\n",
    "    plt.plot(t,lossRec)\r\n",
    "    plt.xlabel('epochs')\r\n",
    "    plt.ylabel('loss')\r\n",
    "    plt.subplot(122)\r\n",
    "    plt.plot(t,validRec)\r\n",
    "    plt.xlabel('epochs')\r\n",
    "    plt.ylabel('Acc')\r\n",
    "    plt.suptitle(\"loss-epoch-acc\")\r\n",
    "    plt.savefig('./AlexNet/img')\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    with open('trainloss.txt','a',encoding='utf-8')as f:\r\n",
    "        f.writelines(lossRec)\r\n",
    "    with open('valloss.txt','a',encoding='utf-8')as f:\r\n",
    "        f.writelines(validRec)\r\n",
    "        \r\n",
    "    return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# AlexNet的代码在Alexnet.py文件中，其他模型同理\r\n",
    "from aleXnet import Alexnet\r\n",
    "\r\n",
    "model = Alexnet(num_classes=200,init_weights=True)\r\n",
    "# print(model)\r\n",
    "model.to(device)\r\n",
    "# train_task1(model,lr=0.001,epoch=20)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alexnet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 48, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classfier): Sequential(\n",
       "    (0): Linear(in_features=4608, out_features=2048, bias=True)\n",
       "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1024, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 尝试使用ResNet网络"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "def train_resnet(model,epoch=100,lr=0.1):\r\n",
    "    loss_function = nn.CrossEntropyLoss()\r\n",
    "    optimizer = torch.optim.SGD(model.parameters(),momentum=0.9,lr=lr,weight_decay=2e-4)\r\n",
    "    \r\n",
    "    lossRec = []\r\n",
    "    validRec = []\r\n",
    "\r\n",
    "    for i in range(epoch):\r\n",
    "        running_loss = 0.0\r\n",
    "        for data in train_loader:\r\n",
    "            imgs,target = data\r\n",
    "            imgs = getdata_task1_aug(imgs.to(device),mode='train') # 采用新的数据增强方式\r\n",
    "            target = target.to(device)\r\n",
    "            output = model(imgs)    \r\n",
    "            loss = loss_function(output,target)\r\n",
    "            running_loss += loss.item()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.zero_grad()\r\n",
    "        lossRec.append(running_loss/len(train_loader))\r\n",
    "        print('Epoch: [{}/{}],TrainLoss:{:.5f}'.format(i+1,epoch,running_loss/len(train_loader))) \r\n",
    "\r\n",
    "        with torch.no_grad():\r\n",
    "            correct_num = 0\r\n",
    "            all_num = 0\r\n",
    "            Pred = torch.zeros(0)\r\n",
    "            Pred = Pred.to(device)\r\n",
    "            for data in val_loader:\r\n",
    "                imgs,_ = data\r\n",
    "                imgs = getdata_task1_aug(imgs.to(device),mode='val')\r\n",
    "                pred = model(imgs)\r\n",
    "                prob = torch.softmax(pred,dim=1)\r\n",
    "                y_pred = torch.argmax(prob,dim=1)\r\n",
    "                Pred = torch.concat((Pred,y_pred),0)\r\n",
    "            acc = torch.sum(Pred == val_label)/Pred.shape[0]\r\n",
    "            print('TestAcc:{:.4f}'.format(acc))\r\n",
    "            validRec.append(acc.cpu().item())\r\n",
    "        torch.save(model,'./ResNet_New/ResNet_New_{}.pt'.format(i+1+65))\r\n",
    "\r\n",
    "    with open('trainloss.txt','a',encoding='utf-8')as f:\r\n",
    "        for loss in lossRec:\r\n",
    "            f.write(str(loss)+'\\n')\r\n",
    "    with open('valloss.txt','a',encoding='utf-8')as f:\r\n",
    "        for loss in validRec:\r\n",
    "            f.write(str(loss)+'\\n')\r\n",
    "\r\n",
    "    t = range(1,len(lossRec)+1)\r\n",
    "    plt.figure(figsize=(18,10))\r\n",
    "    plt.subplot(121)\r\n",
    "    plt.plot(t,lossRec)\r\n",
    "    plt.xlabel('epochs')\r\n",
    "    plt.ylabel('loss')\r\n",
    "    plt.subplot(122)\r\n",
    "    plt.plot(t,validRec)\r\n",
    "    plt.xlabel('epochs')\r\n",
    "    plt.ylabel('Acc')\r\n",
    "    plt.suptitle(\"loss-epoch-acc\")\r\n",
    "    plt.savefig('./ResNet_New/img')\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from ResNet import ResNet\r\n",
    "\r\n",
    "model = torch.load('./ResNet_New/ResNet_New_65.pt') # ResNet(init_weights=True)\r\n",
    "model.to(device)\r\n",
    "train_resnet(model,epoch=10,lr=0.00005)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 使用Resnet\n",
    "\n",
    "最后的正确率大约在55%附近，使用的trick和训练方法基本可以从代码中总结出来\n",
    "\n",
    "在模型设计中取n=1"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 尝试使用Inception-ResNet"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def train_inception_resnet(model,epoch=100,lr=0.01):\r\n",
    "    loss_function = nn.CrossEntropyLoss()\r\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(),alpha=0.9,eps=1.0,lr=lr,weight_decay=2e-4)\r\n",
    "    # optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=2e-4)\r\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9) # 每轮学习率乘以0.9\r\n",
    "    \r\n",
    "    lossRec = []\r\n",
    "    validRec = []\r\n",
    "\r\n",
    "    for i in range(epoch):\r\n",
    "        running_loss = 0.0\r\n",
    "        for data in train_loader:\r\n",
    "            imgs,target = data\r\n",
    "            imgs = getdata_task1_aug(imgs.to(device),mode='train') # 采用新的数据增强方式\r\n",
    "            target = target.to(device)\r\n",
    "            output = model(imgs)    \r\n",
    "            loss = loss_function(output,target)\r\n",
    "            running_loss += loss.item()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.zero_grad()\r\n",
    "        lossRec.append(running_loss/len(train_loader))\r\n",
    "        print('Epoch: [{}/{}],TrainLoss:{:.5f}'.format(i+1,epoch,running_loss/len(train_loader))) \r\n",
    "\r\n",
    "        with torch.no_grad():\r\n",
    "            correct_num = 0\r\n",
    "            all_num = 0\r\n",
    "            Pred = torch.zeros(0)\r\n",
    "            Pred = Pred.to(device)\r\n",
    "            for data in val_loader:\r\n",
    "                imgs,_ = data\r\n",
    "                imgs = getdata_task1_aug(imgs.to(device),mode='val')\r\n",
    "                pred = model(imgs)\r\n",
    "                prob = torch.softmax(pred,dim=1)\r\n",
    "                y_pred = torch.argmax(prob,dim=1)\r\n",
    "                Pred = torch.concat((Pred,y_pred),0)\r\n",
    "            acc = torch.sum(Pred == val_label)/Pred.shape[0]\r\n",
    "            print('TestAcc:{:.4f}'.format(acc))\r\n",
    "            validRec.append(acc.cpu().item())\r\n",
    "        torch.save(model,'./Inception_Tiny_ResNet/Inception_Tiny_ResNet_{}.pt'.format(i+1))\r\n",
    "        # scheduler.step()\r\n",
    "\r\n",
    "    with open('trainloss.txt','a',encoding='utf-8')as f:\r\n",
    "        for loss in lossRec:\r\n",
    "            f.write(str(loss)+'\\n')\r\n",
    "    with open('valloss.txt','a',encoding='utf-8')as f:\r\n",
    "        for loss in validRec:\r\n",
    "            f.write(str(loss)+'\\n')\r\n",
    "\r\n",
    "    t = range(1,len(lossRec)+1)\r\n",
    "    # plt.figure(figsize=(18,10))\r\n",
    "    plt.subplot(121)\r\n",
    "    plt.plot(t,lossRec)\r\n",
    "    plt.xlabel('epochs')\r\n",
    "    plt.ylabel('loss')\r\n",
    "    plt.subplot(122)\r\n",
    "    plt.plot(t,validRec)\r\n",
    "    plt.xlabel('epochs')\r\n",
    "    plt.ylabel('Acc')\r\n",
    "    plt.suptitle(\"loss-epoch-acc\")\r\n",
    "    plt.savefig('./Inception_Tiny_ResNet/img')\r\n",
    "    plt.show()\r\n",
    "    return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from Inception_ResNet import Inception_ResNet\r\n",
    "\r\n",
    "model = Inception_ResNet(init_weights=True)\r\n",
    "# print(model)\r\n",
    "model = model.to(device)\r\n",
    "# train_inception_resnet(model,lr=0.1,epoch=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 使用n=1的Inception ResNet模型\n",
    "\n",
    "首先取n=1，可以发现模型收敛非常慢，首先考虑学习率的初始值较小，可以试试调大，其次也可能是模型的结构比较简单，需要将n设置为更高的数值由此来提高模型的拟合能力\n",
    "\n",
    "在训练了60轮后，可以发现后期的正确率迭代非常慢，基本在30+附近，这也说明模型的拟合能力是不够的..."
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from Inception_ResNet import Inception_ResNet2\r\n",
    "\r\n",
    "model = Inception_ResNet2(init_weights=True)\r\n",
    "model = model.to(device)\r\n",
    "# train_inception_resnet(model,lr=0.1,epoch=60)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "发现n=2以后得到的模型效果更差，可能是参数量过多造成了过拟合问题，因此还是采用n=1"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "n=1在调整了学习率以后依然出现卡在40+的情况，首先可能是训练轮数不够（这个看完60轮的训练图像再做判断）-> 结果确实是在44附近就收敛了\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9) # 每轮正确率乘以0.9\n",
    "\n",
    "其次可能是训练的方法不对，原论文中的方法收敛太慢，与原论文给出的结果不一致\n",
    "\n",
    "可以考虑用类似于ResNet训练的方法，此外也考虑到与ResNet相比参数可能有些过多了，可以调整一下参数量，将模型简化一些"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "尝试使用了SGD和Adam作为优化器，SGD训练误差为nan，Adam的误差也下降极慢，可见训练方法上还是RMProp比较合适。考虑可能是模型结构出现了问题。\n",
    "\n",
    "接下来尝试两个方向：*手动调节学习率*、*简单化网络结构再重新训练*"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "手动调节学习率的方法有一定的提升，达到了48左右，只能尝试把模型改得更简单，还可以再尝试不使用数据增强"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "将模型结构变得更加简单以后发现效果也并不理想，大约再46左右。发现应该是在每一个残差块上都乘以0.1，而不是只有最后一块。于是重新构建网络，并且进行训练，模型明命名为Inception-ResNet-New.\n",
    "\n",
    "但是这样train的模型依然存在过拟合的问题，与ResNet网络进行对比可以看出来。-> 可以试试加momentem?\n",
    "\n",
    "尝试修改网络，将网络改得更加简单。"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from Inception_ResNet import Inception_ResNet3\r\n",
    "\r\n",
    "model = torch.load('./Inception_ResNet/Inception_ResNet_30.pt') #Inception_ResNet3(init_weights=True)\r\n",
    "model = model.to(device)\r\n",
    "train_inception_resnet(model,lr=0.01,epoch=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "测算模型的参数量"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def get_parameter_number(model):\r\n",
    "    total_num = sum(p.numel() for p in model.parameters())\r\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
    "    print('Total:',total_num)\r\n",
    "    print('trainable:',trainable_num)\r\n",
    "    return\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "model = torch.load('./renwu2_3.pt')\r\n",
    "get_parameter_number(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total: 4310059\n",
      "trainable: 4310059\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 接下来尝试使用DenseNet"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def train_densenet(model,epoch=100,lr=1e-4,max_lr=6e-4,step_size=2000):\r\n",
    "    loss_function = nn.CrossEntropyLoss()\r\n",
    "    # optimizer = torch.optim.SGD(model.parameters(),momentum=0.9,lr=lr,weight_decay=2e-4)\r\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,eps=1e-8)\r\n",
    "    schedule = torch.optim.lr_scheduler.CyclicLR(optimizer=optimizer,base_lr=lr,max_lr=max_lr,step_size_up=step_size,mode='triangular2',cycle_momentum=False)\r\n",
    "\r\n",
    "    lossRec = []\r\n",
    "    validRec = []\r\n",
    "\r\n",
    "    for i in range(epoch):\r\n",
    "        running_loss = 0.0\r\n",
    "        for data in train_loader:\r\n",
    "            imgs,target = data\r\n",
    "            # imgs = getdata_task1_aug(imgs.to(device),mode='train') # 采用新的数据增强方式\r\n",
    "            imgs = get_data_for_densenet(imgs.to(device))\r\n",
    "            target = target.to(device)\r\n",
    "            output = model(imgs)    \r\n",
    "            loss = loss_function(output,target)\r\n",
    "            running_loss += loss.item()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            optimizer.zero_grad()\r\n",
    "            schedule.step()\r\n",
    "        lossRec.append(running_loss/len(train_loader))\r\n",
    "        print('Epoch: [{}/{}],TrainLoss:{:.5f}'.format(i+1,epoch,running_loss/len(train_loader))) \r\n",
    "\r\n",
    "        with torch.no_grad():\r\n",
    "            correct_num = 0\r\n",
    "            all_num = 0\r\n",
    "            Pred = torch.zeros(0)\r\n",
    "            Pred = Pred.to(device)\r\n",
    "            for data in val_loader:\r\n",
    "                imgs,_ = data\r\n",
    "                imgs = imgs.to(device) #getdata_task1_aug(imgs.to(device),mode='val')\r\n",
    "                pred = model(imgs)\r\n",
    "                prob = torch.softmax(pred,dim=1)\r\n",
    "                y_pred = torch.argmax(prob,dim=1)\r\n",
    "                Pred = torch.concat((Pred,y_pred),0)\r\n",
    "            acc = torch.sum(Pred == val_label)/Pred.shape[0]\r\n",
    "            print('TestAcc:{:.4f}'.format(acc))\r\n",
    "            validRec.append(acc.cpu().item())\r\n",
    "        torch.save(model,'./DEnseNet/DenseNet_{}.pt'.format(i+1))\r\n",
    "\r\n",
    "    with open('trainloss.txt','a',encoding='utf-8')as f:\r\n",
    "        for loss in lossRec:\r\n",
    "            f.write(str(loss)+'\\n')\r\n",
    "    with open('valloss.txt','a',encoding='utf-8')as f:\r\n",
    "        for loss in validRec:\r\n",
    "            f.write(str(loss)+'\\n')\r\n",
    "\r\n",
    "    t = range(1,len(lossRec)+1)\r\n",
    "    plt.figure(figsize=(18,10))\r\n",
    "    plt.subplot(121)\r\n",
    "    plt.plot(t,lossRec)\r\n",
    "    plt.xlabel('epochs')\r\n",
    "    plt.ylabel('loss')\r\n",
    "    plt.subplot(122)\r\n",
    "    plt.plot(t,validRec)\r\n",
    "    plt.xlabel('epochs')\r\n",
    "    plt.ylabel('Acc')\r\n",
    "    plt.suptitle(\"loss-epoch-acc\")\r\n",
    "    plt.savefig('./DEnseNet/img')\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from DenseNet import DenseNet\r\n",
    "\r\n",
    "model = DenseNet(init_weights=True)\r\n",
    "model = model.to(device)\r\n",
    "train_densenet(model,lr=1e-4,max_lr=6e-4,step_size=4687,epoch=24)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "DenseNet的效果比较好，可以达到60%左右，且前期的收敛速度较快。将这一结果作为任务的最终结果。"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# 用来进行误差的分析\r\n",
    "Fen = {}\r\n",
    "LabelToName = {value:key for key,value in NameToLabel.items()}\r\n",
    "# print(LabelToName)\r\n",
    "# print(Score)\r\n",
    "LLables = []\r\n",
    "with open('./tiny-imagenet-200/val/val_annotations.txt','r',encoding='utf-8')as f:\r\n",
    "    labels = f.readlines()\r\n",
    "    for label in labels:\r\n",
    "        # ValnameToLabel[label.split('\\t')[0]] = NameToLabel[label.split('\\t')[1]]    \r\n",
    "        LLables.append(label.split('\\t')[1])\r\n",
    "print(len(LLables))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "model = torch.load('./renwu1.pt') # /AutoEncoder/AutoEncoder_70.pt\r\n",
    "model = model.to(device)\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    correct_num = 0\r\n",
    "    all_num = 0\r\n",
    "    Pred = torch.zeros(0)\r\n",
    "    Pred = Pred.to(device)\r\n",
    "    for data in val_loader:\r\n",
    "        imgs,_ = data\r\n",
    "        imgs = imgs.to(device) #getdata_task1_aug(imgs.to(device),mode='val')\r\n",
    "        pred = model(imgs) # mode='pred'\r\n",
    "        prob = torch.softmax(pred,dim=1)\r\n",
    "        y_pred = torch.argmax(prob,dim=1)\r\n",
    "        Pred = torch.concat((Pred,y_pred),0)\r\n",
    "    print(Pred == val_label)\r\n",
    "# print(acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ True, False, False,  ..., False,  True,  True], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "Score = {key:0 for key in LabelToName.values()}\r\n",
    "Index = (Pred==val_label).long()\r\n",
    "for i in range(Index.shape[0]):\r\n",
    "    if Index[i] == 1:\r\n",
    "        Score[LLables[i]] += 1\r\n",
    "print(sum(Score.values()))\r\n",
    "Score = sorted(Score.items(),key=lambda x:x[1])\r\n",
    "print(Score[0:5])\r\n",
    "print(Score[-5:])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6277\n",
      "[('n06596364', 21), ('n02132136', 23), ('n02403003', 23), ('n02917067', 23), ('n04371430', 24)]\n",
      "[('n04540053', 38), ('n02123394', 39), ('n04074963', 39), ('n02415577', 40), ('n03733131', 40)]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fa163922eb0b3709bbb5d8082b2465c9de796dbaacca80cbaa600e7fff3e4fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}